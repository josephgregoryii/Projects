{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "projOPT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rmR5FqKEbHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Author:      Joseph Gregory\n",
        "#Project:     Neural Networks"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7gTaR1ZdaKT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "1503af09-1cf8-4411-e1f1-bb88d3f42b7b"
      },
      "source": [
        "##Tutorial code (copied from tutorial for cleaner reference)\n",
        "# 3. Import libraries and modules\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(123)  # for reproducibility\n",
        " \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist\n",
        " \n",
        "# 4. Load pre-shuffled MNIST data into train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        " \n",
        "# 5. Preprocess input data\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        " \n",
        "# 6. Preprocess class labels\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)\n",
        " \n",
        "\n",
        "# 7. Define model architecture\n",
        "model = Sequential()\n",
        " \n",
        "model.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(1,28,28), data_format='channels_first'))\n",
        "model.add(Convolution2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        " \n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        " \n",
        "# 8. Compile model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "# 9. Fit model on training data\n",
        "model.fit(X_train, Y_train, \n",
        "          batch_size=32, epochs=10, verbose=1)\n",
        " \n",
        "# 10. Evaluate model on test data\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2615 - accuracy: 0.9225\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1016 - accuracy: 0.9702\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0768 - accuracy: 0.9772\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0637 - accuracy: 0.9804\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0562 - accuracy: 0.9825\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0464 - accuracy: 0.9856\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0446 - accuracy: 0.9865\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0402 - accuracy: 0.9871\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0352 - accuracy: 0.9884\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0346 - accuracy: 0.9888\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52rgVKQLnYJC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "b77e1c64-6280-4341-975b-503b18b490ea"
      },
      "source": [
        "#model1\n",
        "model1 = Sequential()\n",
        "\n",
        "\n",
        "#gotta shape dat data\n",
        "model1.add(Flatten(input_shape=X_train.shape[1:]))\n",
        "\n",
        "#16 hidden sigmoid layers\n",
        "model1.add(Dense(16, activation=\"sigmoid\"))\n",
        "\n",
        "#0dropout\n",
        "model1.add(Dropout(0))\n",
        "\n",
        "#10 output layers with softmax\n",
        "model1.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model1.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "model1.fit(X_train, Y_train, \n",
        "          batch_size=32, epochs=10, verbose=1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.7822 - accuracy: 0.8382\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3379 - accuracy: 0.9109\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2734 - accuracy: 0.9240\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2434 - accuracy: 0.9314\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2246 - accuracy: 0.9369\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2108 - accuracy: 0.9400\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2006 - accuracy: 0.9431\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1911 - accuracy: 0.9459\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1832 - accuracy: 0.9475\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1767 - accuracy: 0.9494\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc30833fe10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1F_i3nUqNFr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "da860b84-4238-4aa4-9bf2-52987a25d4eb"
      },
      "source": [
        "#model2\n",
        "model2 = Sequential()\n",
        "\n",
        "#gotta make shape dat data\n",
        "model2.add(Flatten(input_shape=X_train.shape[1:]))\n",
        "\n",
        "#16 hidden sigmoid layers\n",
        "model2.add(Dense(128, activation=\"sigmoid\"))\n",
        "\n",
        "#0dropout\n",
        "model2.add(Dropout(0))\n",
        "\n",
        "#10 output layers with softmax\n",
        "model2.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model2.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "model2.fit(X_train, Y_train, \n",
        "          batch_size=32, epochs=10, verbose=1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3970 - accuracy: 0.8959\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1944 - accuracy: 0.9439\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1428 - accuracy: 0.9593\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1103 - accuracy: 0.9683\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0879 - accuracy: 0.9751\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0722 - accuracy: 0.9795\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0599 - accuracy: 0.9830\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0501 - accuracy: 0.9866\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0420 - accuracy: 0.9890\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0353 - accuracy: 0.9907\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc30722d710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knEnb-mVrtIa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "2fed17f1-da5b-419a-931d-b9612e9fd60c"
      },
      "source": [
        "#model3\n",
        "model3 = Sequential()\n",
        "\n",
        "#shape dat data\n",
        "model3.add(Flatten(input_shape=X_train.shape[1:]))\n",
        "\n",
        "#16 hidden relu layers\n",
        "model3.add(Dense(128, activation=\"relu\"))\n",
        "\n",
        "#0 dropout\n",
        "model3.add(Dropout(0))\n",
        "\n",
        "#10 output layers with softmax\n",
        "model3.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model3.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "model3.fit(X_train, Y_train, \n",
        "          batch_size=32, epochs=10, verbose=1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2664 - accuracy: 0.9233\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1162 - accuracy: 0.9658\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0796 - accuracy: 0.9758\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0591 - accuracy: 0.9823\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0457 - accuracy: 0.9859\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0364 - accuracy: 0.9887\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0299 - accuracy: 0.9904\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0235 - accuracy: 0.9925\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0198 - accuracy: 0.9936\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0170 - accuracy: 0.9946\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc3069386a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9xk-6Uv2sWry",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "68a5c54d-057c-4c53-8254-bca8ca81ae53"
      },
      "source": [
        "#model4\n",
        "model4 = Sequential()\n",
        "\n",
        "#shape dat data\n",
        "model4.add(Flatten(input_shape=X_train.shape[1:]))\n",
        "\n",
        "#16 hidden sigmoid layers\n",
        "model4.add(Dense(128, activation=\"relu\"))\n",
        "\n",
        "#0.5 dropout\n",
        "model4.add(Dropout(0.5))\n",
        "\n",
        "#10 output layers with softmax\n",
        "model4.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model4.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "model4.fit(X_train, Y_train, \n",
        "          batch_size=32, epochs=10, verbose=1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3930 - accuracy: 0.8817\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2214 - accuracy: 0.9344\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1862 - accuracy: 0.9452\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1622 - accuracy: 0.9506\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1486 - accuracy: 0.9541\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1413 - accuracy: 0.9565\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1309 - accuracy: 0.9583\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1276 - accuracy: 0.9597\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1194 - accuracy: 0.9635\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1165 - accuracy: 0.9640\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc3060485f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Npsm4fD4zLiH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "e609b751-428b-43f1-ecd2-0db7a8981a5a"
      },
      "source": [
        "model5 = Sequential()\n",
        "\n",
        "model5.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(1,28,28), data_format='channels_first'))\n",
        "model5.add(Flatten())\n",
        "\n",
        "#fiddy dropout\n",
        "\n",
        "model5.add(Dense(128, activation=\"relu\"))\n",
        "\n",
        "model5.add(Dropout(0.5))\n",
        "\n",
        "#10 output layers with softmax\n",
        "model5.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model5.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "model5.fit(X_train, Y_train, \n",
        "          batch_size=32, epochs=10, verbose=1)\n",
        "\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2439 - accuracy: 0.9270\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1049 - accuracy: 0.9681\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0768 - accuracy: 0.9761\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0571 - accuracy: 0.9816\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0511 - accuracy: 0.9833\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0408 - accuracy: 0.9868\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0363 - accuracy: 0.9879\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0325 - accuracy: 0.9888\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0281 - accuracy: 0.9903\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0226 - accuracy: 0.9919\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc305f38eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_3NpwMX2_ze",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "56295ffe-4235-42c6-ac8b-64d671ff202e"
      },
      "source": [
        "model6 = Sequential()\n",
        "\n",
        "model6.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(1,28,28), data_format='channels_first'))\n",
        "model6.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model6.add(Dropout(0.25))\n",
        "model6.add(Flatten())\n",
        "\n",
        "#fiddy dropout\n",
        "\n",
        "model6.add(Dense(128, activation=\"relu\"))\n",
        "\n",
        "model6.add(Dropout(0.5))\n",
        "\n",
        "#10 output layers with softmax\n",
        "model6.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model6.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "model6.fit(X_train, Y_train, \n",
        "          batch_size=32, epochs=10, verbose=1)\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2945 - accuracy: 0.9107\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1301 - accuracy: 0.9614\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1005 - accuracy: 0.9689\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0866 - accuracy: 0.9731\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0734 - accuracy: 0.9774\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0671 - accuracy: 0.9789\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0601 - accuracy: 0.9808\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0540 - accuracy: 0.9826\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0498 - accuracy: 0.9838\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0468 - accuracy: 0.9855\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc304df16d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WsI5c3294Cxf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "925821e2-0a72-4368-ee49-f93f43cc4e2f"
      },
      "source": [
        "model7 = Sequential()\n",
        "\n",
        "model7.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(1,28,28), data_format='channels_first'))\n",
        "model7.add(Convolution2D(32, (3, 3), activation='relu'))\n",
        "model7.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model7.add(Dropout(0.25))\n",
        "model7.add(Flatten())\n",
        "\n",
        "model7.add(Dense(128, activation=\"relu\"))\n",
        "\n",
        "model7.add(Dropout(0.5))\n",
        "\n",
        "#10 output layers with softmax\n",
        "model7.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model7.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "model7.fit(X_train, Y_train, \n",
        "          batch_size=32, epochs=10, verbose=1)\n",
        "\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2478 - accuracy: 0.9259\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.1014 - accuracy: 0.9703\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0755 - accuracy: 0.9769\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0630 - accuracy: 0.9810\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0525 - accuracy: 0.9846\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0470 - accuracy: 0.9856\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0429 - accuracy: 0.9869\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0367 - accuracy: 0.9887\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0349 - accuracy: 0.9888\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0329 - accuracy: 0.9898\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc3044b7cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bhkyzr6G4vay",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a9c7bd71-7edd-41ab-9bf4-491a7bb57558"
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "\n",
        "(X_train2, y_train2), (X_test2, y_test2) = cifar10.load_data()\n",
        "\n",
        "\n",
        " \n",
        "# 5. Preprocess input data\n",
        "X_train2 = X_train2.reshape(X_train2.shape[0], 3, 32, 32)\n",
        "X_test2 = X_test2.reshape(X_test2.shape[0], 3, 32, 32)\n",
        "X_train2 = X_train2.astype('float32')\n",
        "X_test2 = X_test2.astype('float32')\n",
        "X_train2 /= 255\n",
        "X_test2 /= 255\n",
        " \n",
        "# 6. Preprocess class labels\n",
        "Y_train2 = np_utils.to_categorical(y_train2, 10)\n",
        "Y_test2 = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKMMiZ1l6Auq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "5df946a5-2d8a-4b35-c0f6-8d11198cd854"
      },
      "source": [
        "#model8\n",
        "model8 = Sequential()\n",
        "\n",
        "#gotta make shape dat data\n",
        "model8.add(Flatten(input_shape=X_train2.shape[1:]))\n",
        "\n",
        "#16 hidden relu layers\n",
        "model8.add(Dense(128, activation=\"relu\"))\n",
        "\n",
        "#0dropout\n",
        "model8.add(Dropout(0.5))\n",
        "\n",
        "#10 output layers with softmax\n",
        "model8.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model8.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "model8.fit(X_train2, Y_train2, \n",
        "          batch_size=32, epochs=10, verbose=1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.2147 - accuracy: 0.1371\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.1882 - accuracy: 0.1409\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.1809 - accuracy: 0.1419\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.1640 - accuracy: 0.1508\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.1408 - accuracy: 0.1663\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.1329 - accuracy: 0.1707\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.1164 - accuracy: 0.1757\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.1087 - accuracy: 0.1795\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.1029 - accuracy: 0.1818\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 2.1023 - accuracy: 0.1824\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc30352c710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5TTXxTd6sae",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "8de38193-12be-41ac-c341-196899b6f6eb"
      },
      "source": [
        "#model9\n",
        "model9 = Sequential()\n",
        "\n",
        "model9.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(3,32,32), data_format='channels_first'))\n",
        "model9.add(Convolution2D(32, (3, 3), activation='relu'))\n",
        "model9.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model9.add(Dropout(0.25))\n",
        "model9.add(Flatten())\n",
        "\n",
        "model9.add(Dense(128, activation=\"relu\"))\n",
        "\n",
        "model9.add(Dropout(0.5))\n",
        "\n",
        "#10 output layers with softmax\n",
        "model9.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model9.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "model9.fit(X_train2, Y_train2, \n",
        "          batch_size=32, epochs=10, verbose=1)\n",
        "\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.8073 - accuracy: 0.3440\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.6059 - accuracy: 0.4266\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.5331 - accuracy: 0.4524\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.4753 - accuracy: 0.4739\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.4311 - accuracy: 0.4866\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.3963 - accuracy: 0.4975\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.3659 - accuracy: 0.5114\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.3398 - accuracy: 0.5188\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.3142 - accuracy: 0.5281\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 11s 7ms/step - loss: 1.2918 - accuracy: 0.5335\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc3602ce6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kV-OegsgBvCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_score1 = model1.evaluate(X_train, Y_train, verbose=0)\n",
        "_score2 = model2.evaluate(X_train, Y_train, verbose=0)\n",
        "_score3 = model3.evaluate(X_train, Y_train, verbose=0)\n",
        "_score4 = model4.evaluate(X_train, Y_train, verbose=0)\n",
        "_score5 = model5.evaluate(X_train, Y_train, verbose=0)\n",
        "_score6 = model6.evaluate(X_train, Y_train, verbose=0)\n",
        "_score7 = model7.evaluate(X_train, Y_train, verbose=0)\n",
        "_score8 = model8.evaluate(X_train2, Y_train2, verbose=0)\n",
        "_score9 = model9.evaluate(X_train2, Y_train2, verbose=0)\n",
        "\n",
        "score1 = model1.evaluate(X_test, Y_test, verbose=0)\n",
        "score2 = model2.evaluate(X_test, Y_test, verbose=0)\n",
        "score3 = model3.evaluate(X_test, Y_test, verbose=0)\n",
        "score4 = model4.evaluate(X_test, Y_test, verbose=0)\n",
        "score5 = model5.evaluate(X_test, Y_test, verbose=0)\n",
        "score6 = model6.evaluate(X_test, Y_test, verbose=0)\n",
        "score7 = model7.evaluate(X_test, Y_test, verbose=0)\n",
        "score8 = model8.evaluate(X_test2, Y_test2, verbose=0)\n",
        "score9 = model9.evaluate(X_test2, Y_test2, verbose=0)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0_Q0rqqrWky",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "8c806871-587a-4c4c-f0ed-2489b325bfd5"
      },
      "source": [
        "print(\"Accuracy for model1 using training dataset:\",_score1[1])\n",
        "print(\"Accuracy for model1 using testing dataset:\",score1[1],\"\\n\")\n",
        "\n",
        "print(\"Accuracy for model2 using training dataset:\",_score2[1])\n",
        "print(\"Accuracy for model2 using testing dataset:\",score2[1],\"\\n\")\n",
        "\n",
        "print(\"Accuracy for model3 using training dataset:\",_score3[1])\n",
        "print(\"Accuracy for model3 using testing dataset:\",score3[1],\"\\n\")\n",
        "\n",
        "print(\"Accuracy for model4 using training dataset:\",_score4[1])\n",
        "print(\"Accuracy for model4 using testing dataset:\",score4[1],\"\\n\")\n",
        "\n",
        "print(\"Accuracy for model5 using training dataset:\",_score5[1])\n",
        "print(\"Accuracy for model5 using testing dataset:\",score5[1],\"\\n\")\n",
        "\n",
        "print(\"Accuracy for model6 using training dataset:\",_score6[1])\n",
        "print(\"Accuracy for model6 using testing dataset:\",score6[1],\"\\n\")\n",
        "\n",
        "print(\"Accuracy for model7 using training dataset:\",_score7[1])\n",
        "print(\"Accuracy for model7 using testing dataset:\",score7[1],\"\\n\")\n",
        "\n",
        "print(\"Accuracy for model8 using training dataset:\",_score8[1])\n",
        "print(\"Accuracy for model8 using testing dataset:\",score8[1],\"\\n\")\n",
        "\n",
        "print(\"Accuracy for model9 using training dataset:\",_score9[1])\n",
        "print(\"Accuracy for model9 using testing dataset:\",score9[1],\"\\n\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for model1 using training dataset: 0.9523666501045227\n",
            "Accuracy for model1 using testing dataset: 0.9433000087738037 \n",
            "\n",
            "Accuracy for model2 using training dataset: 0.9940166473388672\n",
            "Accuracy for model2 using testing dataset: 0.9772999882698059 \n",
            "\n",
            "Accuracy for model3 using training dataset: 0.9962833523750305\n",
            "Accuracy for model3 using testing dataset: 0.9767000079154968 \n",
            "\n",
            "Accuracy for model4 using training dataset: 0.986466646194458\n",
            "Accuracy for model4 using testing dataset: 0.9757000207901001 \n",
            "\n",
            "Accuracy for model5 using training dataset: 0.9995499849319458\n",
            "Accuracy for model5 using testing dataset: 0.9868999719619751 \n",
            "\n",
            "Accuracy for model6 using training dataset: 0.9967166781425476\n",
            "Accuracy for model6 using testing dataset: 0.9879999756813049 \n",
            "\n",
            "Accuracy for model7 using training dataset: 0.9973833560943604\n",
            "Accuracy for model7 using testing dataset: 0.9894000291824341 \n",
            "\n",
            "Accuracy for model8 using training dataset: 0.27636000514030457\n",
            "Accuracy for model8 using testing dataset: 0.09629999846220016 \n",
            "\n",
            "Accuracy for model9 using training dataset: 0.6417800188064575\n",
            "Accuracy for model9 using testing dataset: 0.10010000318288803 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}