{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "projOPT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rmR5FqKEbHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Author:      Joseph Gregory\n",
        "#Project:     Neural Networks"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7gTaR1ZdaKT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "791be3b2-10c3-4f1c-bef7-c4f3da253ba1"
      },
      "source": [
        "##Tutorial code (copied from tutorial for cleaner reference)\n",
        "# 3. Import libraries and modules\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(123)  # for reproducibility\n",
        " \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist\n",
        " \n",
        "# 4. Load pre-shuffled MNIST data into train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        " \n",
        "# 5. Preprocess input data\n",
        "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28)\n",
        "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        " \n",
        "# 6. Preprocess class labels\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)\n",
        " \n",
        "\n",
        "# 7. Define model architecture\n",
        "model = Sequential()\n",
        " \n",
        "model.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(1,28,28), data_format='channels_first'))\n",
        "model.add(Convolution2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        " \n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        " \n",
        "# 8. Compile model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "# 9. Fit model on training data\n",
        "model.fit(X_train, Y_train, \n",
        "          batch_size=32, epochs=10, verbose=1)\n",
        " \n",
        "# 10. Evaluate model on test data\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1657/1875 [=========================>....] - ETA: 1s - loss: 0.2996 - accuracy: 0.9091"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-df33a444dcf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# 9. Fit model on training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m model.fit(X_train, Y_train, \n\u001b[0;32m---> 51\u001b[0;31m           batch_size=32, epochs=10, verbose=1)\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# 10. Evaluate model on test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1101\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \"\"\"\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    340\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \"\"\"\n\u001b[1;32m   1062\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52rgVKQLnYJC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "f51824fb-7240-4f13-ce2a-b6212e7363a1"
      },
      "source": [
        "#model1\n",
        "model1 = Sequential()\n",
        "\n",
        "\n",
        "#gotta shape dat data\n",
        "model1.add(Flatten(input_shape=X_train.shape[1:]))\n",
        "\n",
        "#16 hidden sigmoid layers\n",
        "model1.add(Dense(16, activation=\"sigmoid\"))\n",
        "\n",
        "#0dropout\n",
        "model1.add(Dropout(0))\n",
        "\n",
        "#10 output layers with softmax\n",
        "model1.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model1.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "model1.fit(X_train, Y_train, \n",
        "          batch_size=32, epochs=10, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.8573 - acc: 0.8010\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 9s 146us/step - loss: 0.3505 - acc: 0.9093\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 8s 137us/step - loss: 0.2742 - acc: 0.9236\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 8s 141us/step - loss: 0.2401 - acc: 0.9310\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.2192 - acc: 0.9368\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 9s 148us/step - loss: 0.2048 - acc: 0.9405\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 9s 142us/step - loss: 0.1936 - acc: 0.9445\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 8s 138us/step - loss: 0.1834 - acc: 0.9472\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 8s 138us/step - loss: 0.1755 - acc: 0.9489\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 8s 139us/step - loss: 0.1684 - acc: 0.9517\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f600844d630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1F_i3nUqNFr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "e6c497c0-01d5-4460-a3cb-cf5cf469dbed"
      },
      "source": [
        "#model2\n",
        "model2 = Sequential()\n",
        "\n",
        "#gotta make shape dat data\n",
        "model2.add(Flatten(input_shape=X_train.shape[1:]))\n",
        "\n",
        "#16 hidden sigmoid layers\n",
        "model2.add(Dense(128, activation=\"sigmoid\"))\n",
        "\n",
        "#0dropout\n",
        "model2.add(Dropout(0))\n",
        "\n",
        "#10 output layers with softmax\n",
        "model2.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model2.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "model2.fit(X_train, Y_train, \n",
        "          batch_size=32, epochs=10, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.4033 - acc: 0.8942\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 8s 140us/step - loss: 0.1968 - acc: 0.9437\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 8s 137us/step - loss: 0.1442 - acc: 0.9585\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.1116 - acc: 0.9675\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 8s 139us/step - loss: 0.0894 - acc: 0.9751\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 8s 138us/step - loss: 0.0734 - acc: 0.9794\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 8s 136us/step - loss: 0.0605 - acc: 0.9831\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 8s 135us/step - loss: 0.0511 - acc: 0.9857\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 8s 136us/step - loss: 0.0427 - acc: 0.9887\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 8s 138us/step - loss: 0.0357 - acc: 0.9912\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6008337128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knEnb-mVrtIa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "af6eb26e-d4ae-4dc7-c23d-b968da04bb6c"
      },
      "source": [
        "#model3\n",
        "model3 = Sequential()\n",
        "\n",
        "#shape dat data\n",
        "model3.add(Flatten(input_shape=X_train.shape[1:]))\n",
        "\n",
        "#16 hidden relu layers\n",
        "model3.add(Dense(128, activation=\"relu\"))\n",
        "\n",
        "#0 dropout\n",
        "model3.add(Dropout(0))\n",
        "\n",
        "#10 output layers with softmax\n",
        "model3.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model3.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "model3.fit(X_train, Y_train, \n",
        "          batch_size=32, epochs=10, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 9s 142us/step - loss: 0.2537 - acc: 0.9282\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 8s 137us/step - loss: 0.1105 - acc: 0.9669\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 8s 137us/step - loss: 0.0764 - acc: 0.9763\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 9s 142us/step - loss: 0.0584 - acc: 0.9823\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 8s 134us/step - loss: 0.0455 - acc: 0.9859\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 8s 135us/step - loss: 0.0347 - acc: 0.9894\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 8s 138us/step - loss: 0.0272 - acc: 0.9915\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 8s 137us/step - loss: 0.0232 - acc: 0.9927\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 8s 135us/step - loss: 0.0183 - acc: 0.9941\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 8s 132us/step - loss: 0.0162 - acc: 0.9950\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6008238c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9xk-6Uv2sWry",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "0b3bfd9b-2eb8-4662-9649-26347f9beb99"
      },
      "source": [
        "#model4\n",
        "model4 = Sequential()\n",
        "\n",
        "#shape dat data\n",
        "model4.add(Flatten(input_shape=X_train.shape[1:]))\n",
        "\n",
        "#16 hidden sigmoid layers\n",
        "model4.add(Dense(128, activation=\"relu\"))\n",
        "\n",
        "#0.5 dropout\n",
        "model4.add(Dropout(0.5))\n",
        "\n",
        "#10 output layers with softmax\n",
        "model4.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model4.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "model4.fit(X_train, Y_train, \n",
        "          batch_size=32, epochs=10, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 9s 151us/step - loss: 0.3862 - acc: 0.8857\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 8s 138us/step - loss: 0.2180 - acc: 0.9350\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 9s 144us/step - loss: 0.1797 - acc: 0.9463\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 8s 140us/step - loss: 0.1581 - acc: 0.9518\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 9s 148us/step - loss: 0.1460 - acc: 0.9555\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 9s 146us/step - loss: 0.1341 - acc: 0.9586\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.1257 - acc: 0.9609\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.1174 - acc: 0.9634\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 8s 139us/step - loss: 0.1162 - acc: 0.9635\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 9s 143us/step - loss: 0.1114 - acc: 0.9650\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f60080fdc18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Npsm4fD4zLiH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "ec08110b-1d5e-481a-d1c1-054ce291d066"
      },
      "source": [
        "model5 = Sequential()\n",
        "\n",
        "model5.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(1,28,28), data_format='channels_first'))\n",
        "model5.add(Flatten())\n",
        "\n",
        "#fiddy dropout\n",
        "\n",
        "model5.add(Dense(128, activation=\"relu\"))\n",
        "\n",
        "model5.add(Dropout(0.5))\n",
        "\n",
        "#10 output layers with softmax\n",
        "model5.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model5.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "model5.fit(X_train, Y_train, \n",
        "          batch_size=32, epochs=10, verbose=1)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 12s 198us/step - loss: 0.2266 - acc: 0.9321\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 11s 186us/step - loss: 0.0984 - acc: 0.9704\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.0705 - acc: 0.9785\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 11s 185us/step - loss: 0.0542 - acc: 0.9824\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 11s 191us/step - loss: 0.0444 - acc: 0.9861\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0374 - acc: 0.9879\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 11s 184us/step - loss: 0.0322 - acc: 0.9891\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 11s 184us/step - loss: 0.0267 - acc: 0.9908\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 11s 186us/step - loss: 0.0237 - acc: 0.9920\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 11s 184us/step - loss: 0.0218 - acc: 0.9923\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5e0f054470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_3NpwMX2_ze",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "f1629967-1e58-4f38-a901-d7edc7f6af1a"
      },
      "source": [
        "model6 = Sequential()\n",
        "\n",
        "model6.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(1,28,28), data_format='channels_first'))\n",
        "model6.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model6.add(Dropout(0.25))\n",
        "model6.add(Flatten())\n",
        "\n",
        "#fiddy dropout\n",
        "\n",
        "model6.add(Dense(128, activation=\"relu\"))\n",
        "\n",
        "model6.add(Dropout(0.5))\n",
        "\n",
        "#10 output layers with softmax\n",
        "model6.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model6.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "model6.fit(X_train, Y_train, \n",
        "          batch_size=32, epochs=10, verbose=1)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 12s 192us/step - loss: 0.3553 - acc: 0.8922\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 11s 179us/step - loss: 0.1590 - acc: 0.9525\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 11s 176us/step - loss: 0.1119 - acc: 0.9661\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 11s 181us/step - loss: 0.0918 - acc: 0.9714\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.0796 - acc: 0.9748\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 11s 181us/step - loss: 0.0687 - acc: 0.9781\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 11s 181us/step - loss: 0.0604 - acc: 0.9808\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 11s 183us/step - loss: 0.0555 - acc: 0.9822\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 11s 182us/step - loss: 0.0507 - acc: 0.9829\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 11s 176us/step - loss: 0.0481 - acc: 0.9847\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5e0eed5780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WsI5c3294Cxf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "4d8ba5d1-13b2-46e6-ec97-a6adb19ae91b"
      },
      "source": [
        "model7 = Sequential()\n",
        "\n",
        "model7.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(1,28,28), data_format='channels_first'))\n",
        "model7.add(Convolution2D(32, (3, 3), activation='relu'))\n",
        "model7.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model7.add(Dropout(0.25))\n",
        "model7.add(Flatten())\n",
        "\n",
        "model7.add(Dense(128, activation=\"relu\"))\n",
        "\n",
        "model7.add(Dropout(0.5))\n",
        "\n",
        "#10 output layers with softmax\n",
        "model7.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model7.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "model7.fit(X_train, Y_train, \n",
        "          batch_size=32, epochs=10, verbose=1)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 13s 215us/step - loss: 0.2541 - acc: 0.9233\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 12s 194us/step - loss: 0.1013 - acc: 0.9705\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 12s 205us/step - loss: 0.0791 - acc: 0.9765\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 13s 209us/step - loss: 0.0649 - acc: 0.9802\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 12s 202us/step - loss: 0.0541 - acc: 0.9836\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 12s 208us/step - loss: 0.0499 - acc: 0.9847\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 12s 201us/step - loss: 0.0431 - acc: 0.9869\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 12s 197us/step - loss: 0.0406 - acc: 0.9873\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 12s 195us/step - loss: 0.0378 - acc: 0.9884\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 12s 203us/step - loss: 0.0331 - acc: 0.9895\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5e0ed142e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bhkyzr6G4vay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "\n",
        "(X_train2, y_train2), (X_test2, y_test2) = cifar10.load_data()\n",
        "\n",
        "\n",
        " \n",
        "# 5. Preprocess input data\n",
        "X_train2 = X_train2.reshape(X_train2.shape[0], 3, 32, 32)\n",
        "X_test2 = X_test2.reshape(X_test2.shape[0], 3, 32, 32)\n",
        "X_train2 = X_train2.astype('float32')\n",
        "X_test2 = X_test2.astype('float32')\n",
        "X_train2 /= 255\n",
        "X_test2 /= 255\n",
        " \n",
        "# 6. Preprocess class labels\n",
        "Y_train2 = np_utils.to_categorical(y_train2, 10)\n",
        "Y_test2 = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKMMiZ1l6Auq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "9b783233-08d6-43a1-da15-e93b34080865"
      },
      "source": [
        "#model8\n",
        "model8 = Sequential()\n",
        "\n",
        "#gotta make shape dat data\n",
        "model8.add(Flatten(input_shape=X_train2.shape[1:]))\n",
        "\n",
        "#16 hidden relu layers\n",
        "model8.add(Dense(128, activation=\"relu\"))\n",
        "\n",
        "#0dropout\n",
        "model8.add(Dropout(0.5))\n",
        "\n",
        "#10 output layers with softmax\n",
        "model8.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model8.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "model8.fit(X_train2, Y_train2, \n",
        "          batch_size=32, epochs=10, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "50000/50000 [==============================] - 8s 159us/step - loss: 2.2159 - acc: 0.1395\n",
            "Epoch 2/10\n",
            "50000/50000 [==============================] - 7s 141us/step - loss: 2.1891 - acc: 0.1412\n",
            "Epoch 3/10\n",
            "50000/50000 [==============================] - 7s 145us/step - loss: 2.1815 - acc: 0.1382\n",
            "Epoch 4/10\n",
            "50000/50000 [==============================] - 7s 145us/step - loss: 2.1798 - acc: 0.1407\n",
            "Epoch 5/10\n",
            "50000/50000 [==============================] - 7s 146us/step - loss: 2.1785 - acc: 0.1429\n",
            "Epoch 6/10\n",
            "50000/50000 [==============================] - 7s 146us/step - loss: 2.1773 - acc: 0.1423\n",
            "Epoch 7/10\n",
            "50000/50000 [==============================] - 7s 144us/step - loss: 2.1735 - acc: 0.1422\n",
            "Epoch 8/10\n",
            "50000/50000 [==============================] - 7s 146us/step - loss: 2.1742 - acc: 0.1415\n",
            "Epoch 9/10\n",
            "50000/50000 [==============================] - 7s 146us/step - loss: 2.1746 - acc: 0.1437\n",
            "Epoch 10/10\n",
            "50000/50000 [==============================] - 7s 144us/step - loss: 2.1742 - acc: 0.1422\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5fa4698400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5TTXxTd6sae",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "b5d8c6dd-8b26-46f2-b03e-59a8c4447980"
      },
      "source": [
        "#model9\n",
        "model9 = Sequential()\n",
        "\n",
        "model9.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(3,32,32), data_format='channels_first'))\n",
        "model9.add(Convolution2D(32, (3, 3), activation='relu'))\n",
        "model9.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model9.add(Dropout(0.25))\n",
        "model9.add(Flatten())\n",
        "\n",
        "model9.add(Dense(128, activation=\"relu\"))\n",
        "\n",
        "model9.add(Dropout(0.5))\n",
        "\n",
        "#10 output layers with softmax\n",
        "model9.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "model9.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        " \n",
        "model9.fit(X_train2, Y_train2, \n",
        "          batch_size=32, epochs=10, verbose=1)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "50000/50000 [==============================] - 11s 227us/step - loss: 1.8374 - acc: 0.3323\n",
            "Epoch 2/10\n",
            "50000/50000 [==============================] - 10s 210us/step - loss: 1.6324 - acc: 0.4086\n",
            "Epoch 3/10\n",
            "50000/50000 [==============================] - 10s 208us/step - loss: 1.5588 - acc: 0.4371\n",
            "Epoch 4/10\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 1.5055 - acc: 0.4591\n",
            "Epoch 5/10\n",
            "50000/50000 [==============================] - 10s 206us/step - loss: 1.4739 - acc: 0.4651\n",
            "Epoch 6/10\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.4407 - acc: 0.4777\n",
            "Epoch 7/10\n",
            "50000/50000 [==============================] - 10s 204us/step - loss: 1.4161 - acc: 0.4879\n",
            "Epoch 8/10\n",
            "50000/50000 [==============================] - 10s 205us/step - loss: 1.3846 - acc: 0.4977\n",
            "Epoch 9/10\n",
            "50000/50000 [==============================] - 10s 209us/step - loss: 1.3633 - acc: 0.5031\n",
            "Epoch 10/10\n",
            "50000/50000 [==============================] - 10s 201us/step - loss: 1.3431 - acc: 0.5129\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5e0eb14c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kV-OegsgBvCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_score1 = model1.evaluate(X_train, Y_train, verbose=0)\n",
        "_score2 = model2.evaluate(X_train, Y_train, verbose=0)\n",
        "_score3 = model3.evaluate(X_train, Y_train, verbose=0)\n",
        "_score4 = model4.evaluate(X_train, Y_train, verbose=0)\n",
        "_score5 = model5.evaluate(X_train, Y_train, verbose=0)\n",
        "_score6 = model6.evaluate(X_train, Y_train, verbose=0)\n",
        "_score7 = model7.evaluate(X_train, Y_train, verbose=0)\n",
        "_score8 = model8.evaluate(X_train2, Y_train2, verbose=0)\n",
        "_score9 = model9.evaluate(X_train2, Y_train2, verbose=0)\n",
        "\n",
        "score1 = model1.evaluate(X_test, Y_test, verbose=0)\n",
        "score2 = model2.evaluate(X_test, Y_test, verbose=0)\n",
        "score3 = model3.evaluate(X_test, Y_test, verbose=0)\n",
        "score4 = model4.evaluate(X_test, Y_test, verbose=0)\n",
        "score5 = model5.evaluate(X_test, Y_test, verbose=0)\n",
        "score6 = model6.evaluate(X_test, Y_test, verbose=0)\n",
        "score7 = model7.evaluate(X_test, Y_test, verbose=0)\n",
        "score8 = model8.evaluate(X_test2, Y_test2, verbose=0)\n",
        "score9 = model9.evaluate(X_test2, Y_test2, verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0_Q0rqqrWky",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "b318a28d-5691-4aa0-a95d-8fb78548e072"
      },
      "source": [
        "print(\"Accuracy for model1 using training dataset:\",_score1[1])\n",
        "print(\"Accuracy for model1 using testing dataset:\",score1[1],\"\\n\")\n",
        "\n",
        "print(\"Accuracy for model2 using training dataset:\",_score2[1])\n",
        "print(\"Accuracy for model2 using testing dataset:\",score2[1],\"\\n\")\n",
        "\n",
        "print(\"Accuracy for model3 using training dataset:\",_score3[1])\n",
        "print(\"Accuracy for model3 using testing dataset:\",score3[1],\"\\n\")\n",
        "\n",
        "print(\"Accuracy for model4 using training dataset:\",_score4[1])\n",
        "print(\"Accuracy for model4 using testing dataset:\",score4[1],\"\\n\")\n",
        "\n",
        "print(\"Accuracy for model5 using training dataset:\",_score5[1])\n",
        "print(\"Accuracy for model5 using testing dataset:\",score5[1],\"\\n\")\n",
        "\n",
        "print(\"Accuracy for model6 using training dataset:\",_score6[1])\n",
        "print(\"Accuracy for model6 using testing dataset:\",score6[1],\"\\n\")\n",
        "\n",
        "print(\"Accuracy for model7 using training dataset:\",_score7[1])\n",
        "print(\"Accuracy for model7 using testing dataset:\",score7[1],\"\\n\")\n",
        "\n",
        "print(\"Accuracy for model8 using training dataset:\",_score8[1])\n",
        "print(\"Accuracy for model8 using testing dataset:\",score8[1],\"\\n\")\n",
        "\n",
        "print(\"Accuracy for model9 using training dataset:\",_score9[1])\n",
        "print(\"Accuracy for model9 using testing dataset:\",score9[1],\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for model1 using training dataset: 0.9532666666666667\n",
            "Accuracy for model1 using testing dataset: 0.944 \n",
            "\n",
            "Accuracy for model2 using training dataset: 0.99405\n",
            "Accuracy for model2 using testing dataset: 0.9768 \n",
            "\n",
            "Accuracy for model3 using training dataset: 0.9965333333333334\n",
            "Accuracy for model3 using testing dataset: 0.9777 \n",
            "\n",
            "Accuracy for model4 using training dataset: 0.98715\n",
            "Accuracy for model4 using testing dataset: 0.9785 \n",
            "\n",
            "Accuracy for model5 using training dataset: 0.9996333333333334\n",
            "Accuracy for model5 using testing dataset: 0.9872 \n",
            "\n",
            "Accuracy for model6 using training dataset: 0.9987166666666667\n",
            "Accuracy for model6 using testing dataset: 0.9888 \n",
            "\n",
            "Accuracy for model7 using training dataset: 0.9987\n",
            "Accuracy for model7 using testing dataset: 0.991 \n",
            "\n",
            "Accuracy for model8 using training dataset: 0.19452\n",
            "Accuracy for model8 using testing dataset: 0.0955 \n",
            "\n",
            "Accuracy for model9 using training dataset: 0.67074\n",
            "Accuracy for model9 using testing dataset: 0.1 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}